{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Lesion Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using Tinder, all the necessary requirements are already installed in a conda environment.\n",
    "\n",
    "To activate the environment in the terminal, use the command: ```conda activate env```\n",
    "\n",
    "## Accessing TensorBoard:\n",
    "\n",
    "1. Navigate to the TensorBoard logs directory:\n",
    "    ```cd skin_lesion_classification/logs```\n",
    "\n",
    "2. Start TensorBoard:\n",
    "    ```tensorboard --logdir ./ --bind_all```\n",
    "\n",
    "3. ctrl + click on the TensorBoard link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below if you haven't installed the requirements on your machine yet."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 1,
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": 2,
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import pytorch_lightning\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 3,
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 2\n",
      "GPU 0: NVIDIA GeForce GTX 1080 Ti\n",
      "GPU 1: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Ensure reproducibility for the dataset split\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    # If you're using CUDA:\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    num_cuda_devices = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_cuda_devices}\")\n",
    "    for i in range(num_cuda_devices):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        \n",
    "# Para operações determinísticas no PyTorch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CSV"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 4,
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available and 2 CUDA device(s) is(are) available.\n",
      "Class counts: dx\n",
      "0    7919\n",
      "1    1954\n",
      "Name: count, dtype: int64\n",
      "Class weights (before normalization): tensor([0.0001, 0.0005])\n",
      "Class weights (after normalization): tensor([0.1979, 0.8021], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, indices, csv_file, root_dir_1, root_dir_2, transform):\n",
    "        self.indices = indices                                           # Indices of the samples to be loaded\n",
    "        self.root_dir_1 = root_dir_1                                     # Path to the first directory where images are stored.\n",
    "        self.root_dir_2 = root_dir_2                                     # Path to the second directory where images are stored.\n",
    "        self.transform = transform                                       # Transformations to be applied to the images.\n",
    "        self.annotations = pd.read_csv(csv_file).iloc[indices]           # Load the CSV file and extract the relevant rows\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)                                     # Return the number of samples in the dataset.\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_code = self.annotations.iloc[idx, 1]  # Extract the file code from the DataFrame\n",
    "        img_name = img_code + '.jpg'  # Add the '.jpg' extension\n",
    "        img_path = None\n",
    "\n",
    "        # Check if image is in directory 1\n",
    "        if os.path.exists(os.path.join(self.root_dir_1, img_name)):\n",
    "            img_path = os.path.join(self.root_dir_1, img_name)\n",
    "\n",
    "        # Check if image is in directory 2\n",
    "        elif os.path.exists(os.path.join(self.root_dir_2, img_name)):\n",
    "            img_path = os.path.join(self.root_dir_2, img_name)\n",
    "        \n",
    "        # Print an error message if image is not found in either directory\n",
    "        if img_path is None:\n",
    "            print(\"IDX \",idx )\n",
    "            print(f\"File {img_name} not found in any of the specified directories.\")\n",
    "            return None, None  # Return None for image and label\n",
    "\n",
    "        # Open the image and convert to RGB if found\n",
    "        # This operation is included as a precaution to ensure all images are treated consistently\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(self.annotations.iloc[idx, 2])  # Convert label to tensor\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Define data augmentations and transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(299, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load CSV file and define paths\n",
    "csv_file = '/home/ashiley/HAM10000_metadata_alterado.csv'\n",
    "data_path_1 = '/home/ashiley/HAM10000_images_part_1'\n",
    "data_path_2 = '/home/ashiley/HAM10000_images_part_2'\n",
    "\n",
    "# Load the full dataset once\n",
    "df = pd.read_csv(csv_file)\n",
    "total_samples = len(df)\n",
    "indices = list(range(total_samples))\n",
    "\n",
    "# Split the dataset into training, validation, and test\n",
    "train_size = int(0.8 * total_samples)  # 80% for training\n",
    "val_size = int(0.1 * total_samples)  # 10% for validation\n",
    "test_size = total_samples - train_size - val_size  # Remaining 10% for testing\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(indices, [train_size, val_size, test_size], generator=generator)\n",
    "    \n",
<<<<<<< HEAD
    "# just balancing\n",
=======
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
    "train_dataset = CustomDataset(train_dataset.indices, csv_file, data_path_1, data_path_2, transform_train)\n",
    "val_dataset = CustomDataset(val_dataset.indices, csv_file, data_path_1, data_path_2, transform)\n",
    "test_dataset = CustomDataset(test_dataset.indices, csv_file, data_path_1, data_path_2, transform)\n",
    "\n",
    "input_channels = 3  # Number of channels in the input images (RGB)\n",
    "num_classes = 2     # Number of classes in the classification task (malignant or benign)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = df['dx'].value_counts()\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "class_weights = class_weights / class_weights.sum()  # Normalize to make the sum of weights equal to 1\n",
    "\n",
    "if cuda_available:\n",
    "    num_cuda_devices = torch.cuda.device_count()\n",
    "    print(\"CUDA is available and {} CUDA device(s) is(are) available.\".format(num_cuda_devices))\n",
    "else:\n",
    "    print(\"CUDA is not available. You are running on CPU.\")\n",
    "\n",
    "# Move a tensor to a specific GPU or CPU\n",
    "# Always use GPU 0 if available\n",
    "device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
    "\n",
    "# Move the tensor to the chosen device\n",
    "class_weights = class_weights.to(device)  # Move to the correct device\n",
    "\n",
    "# The class with a weight of 0.8021 (Class 1) is more heavily penalized in terms of errors, while the class with a weight of 0.1979 (Class 0) has a lower penalty.\n",
    "print(\"Class counts:\", class_counts)\n",
    "print(\"Class weights (before normalization):\", 1.0 / torch.tensor(class_counts, dtype=torch.float))\n",
    "print(\"Class weights (after normalization):\", class_weights)\n",
    "\n",
    "# Create DataLoaders for the training, validation, and test sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, worker_init_fn=seed_worker, generator=generator)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, worker_init_fn=seed_worker, generator=generator)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, worker_init_fn=seed_worker, generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Generic Classifier"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 5,
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name, num_classes, learning_rate, class_weights):\n",
    "        super(GenericClassifier, self).__init__()\n",
    "        \n",
    "        # Dictionary to map model names to their creation functions\n",
    "        model_dict = {\n",
    "            'vgg': models.vgg16,\n",
    "            'resnet': models.resnet18,\n",
    "            'alexnet': models.alexnet,\n",
    "            'efficientnet': EfficientNet.from_pretrained,\n",
    "            'inception': models.inception_v3\n",
    "        }\n",
    "        \n",
    "        # Select model\n",
    "        if model_name not in model_dict:\n",
    "            raise ValueError(f\"Model {model_name} is not supported. Choose from {list(model_dict.keys())}.\")\n",
    "        \n",
    "        if model_name == 'efficientnet':\n",
    "            self.model = model_dict[model_name]('efficientnet-b0', num_classes=num_classes)\n",
    "            \n",
    "            for name, param in self.model.named_parameters():\n",
    "                if '_fc' not in name:  \n",
    "                    param.requires_grad = False\n",
    "        else:\n",
    "            self.model = model_dict[model_name](pretrained=True)\n",
    "            if model_name == 'vgg':\n",
    "                for param in self.model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                for param in self.model.classifier[6].parameters():\n",
    "                    param.requires_grad = True\n",
    "                self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)\n",
    "            \n",
    "            elif model_name == 'resnet':\n",
    "                for param in self.model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                for param in self.model.fc.parameters():\n",
    "                    param.requires_grad = True\n",
    "                self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "            \n",
    "            elif model_name == 'alexnet':\n",
    "                for param in self.model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                for param in self.model.classifier[6].parameters():\n",
    "                    param.requires_grad = True\n",
    "                self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)\n",
    "            \n",
    "            elif model_name == 'inception':\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if \"fc\" not in name:  \n",
    "                        param.requires_grad = False\n",
    "                \n",
    "                in_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.class_weights = class_weights\n",
    "        self.val_preds = []\n",
    "        self.val_true = []\n",
    "        self.test_preds = []\n",
    "        self.test_true = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if isinstance(self.model, models.Inception3):\n",
    "            x = self.model(x)\n",
    "            return x.logits if hasattr(x, 'logits') else x  # Use the main output for Inception\n",
    "        else:\n",
    "            return self.model(x)\n",
    "\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': scheduler,\n",
    "            'monitor': 'val_loss'\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y, weight=self.class_weights)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y, weight=self.class_weights)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.val_probs.extend(torch.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "        self.val_preds.extend(preds.detach().cpu().numpy())\n",
    "        self.val_true.extend(y.detach().cpu().numpy())\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y, weight=self.class_weights)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.test_probs.extend(torch.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "        self.test_preds.extend(preds.detach().cpu().numpy())\n",
    "        self.test_true.extend(y.detach().cpu().numpy())\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('test_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        # Printing the accuracy\n",
    "        print(f\"Test Accuracy: {acc:.6f}\")\n",
    "        return loss, acc\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.val_preds = []\n",
    "        self.val_probs = []\n",
    "        self.val_true = []\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        self.test_preds = []\n",
    "        self.test_probs = []\n",
    "        self.test_true = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save metrics functions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 6,
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(val_true, val_preds, test_true, test_preds, val_probs, test_probs, experiment_name, time_taken):\n",
<<<<<<< HEAD
    "    output_dir = os.path.join('balanced_results', experiment_name)\n",
=======
    "    output_dir = os.path.join('augmented_results', experiment_name)\n",
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    val_confusion = confusion_matrix(val_true, val_preds)\n",
    "    test_confusion = confusion_matrix(test_true, test_preds)\n",
    "    \n",
    "    val_precision = precision_score(val_true, val_preds, average='macro')\n",
    "    test_precision = precision_score(test_true, test_preds, average='macro')\n",
    "    \n",
    "    val_recall = recall_score(val_true, val_preds, average='macro')\n",
    "    test_recall = recall_score(test_true, test_preds, average='macro')\n",
    "    \n",
    "    val_f1 = f1_score(val_true, val_preds, average='macro')\n",
    "    test_f1 = f1_score(test_true, test_preds, average='macro')\n",
    "    \n",
    "    print(\"Validation Confusion Matrix:\\n\", val_confusion)\n",
    "    print(\"Test Confusion Matrix:\\n\", test_confusion)\n",
    "    print(\"Validation Precision: \", val_precision)\n",
    "    print(\"Test Precision: \", test_precision)\n",
    "    print(\"Validation Recall: \", val_recall)\n",
    "    print(\"Test Recall: \", test_recall)\n",
    "    print(\"Validation F1-Score: \", val_f1)\n",
    "    print(\"Test F1-Score: \", test_f1)\n",
    "    \n",
    "    metrics = {\n",
    "        \"val_precision\": val_precision,\n",
    "        \"test_precision\": test_precision,\n",
    "        \"val_recall\": val_recall,\n",
    "        \"test_recall\": test_recall,\n",
    "        \"val_f1\": val_f1,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"time_taken\": time_taken\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'metrics.json'), 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    sns.heatmap(val_confusion, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "    axes[0].set_title('Validation Confusion Matrix')\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('True')\n",
    "    \n",
    "    sns.heatmap(test_confusion, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
    "    axes[1].set_title('Test Confusion Matrix')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('True')\n",
    "    \n",
    "    confusion_matrices_path = os.path.join(output_dir, 'confusion_matrices.png')\n",
    "    plt.savefig(confusion_matrices_path)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(data=pd.DataFrame({\n",
    "        'Precision': [val_precision, test_precision],\n",
    "        'Recall': [val_recall, test_recall],\n",
    "        'F1-Score': [val_f1, test_f1]\n",
    "    }, index=['Validation', 'Test']))\n",
    "    plt.title('Metrics Comparison')\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    metrics_comparison_path = os.path.join(output_dir, 'metrics_comparison.png')\n",
    "    plt.savefig(metrics_comparison_path)\n",
    "    plt.close()\n",
    "    \n",
    "    np.savetxt(os.path.join(output_dir, 'val_probs.csv'), np.array(val_probs), delimiter=',')\n",
    "    np.savetxt(os.path.join(output_dir, 'val_true.csv'), np.array(val_true), delimiter=',')\n",
    "    np.savetxt(os.path.join(output_dir, 'test_probs.csv'), np.array(test_probs), delimiter=',')\n",
    "    np.savetxt(os.path.join(output_dir, 'test_true.csv'), np.array(test_true), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_roc_curves(experiment_names, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for experiment_name in experiment_names:\n",
    "        output_dir = os.path.join('augmented_results', experiment_name)\n",
    "        \n",
    "        # Load probabilities and true labels\n",
    "        val_probs = np.loadtxt(os.path.join(output_dir, 'val_probs.csv'), delimiter=',')\n",
    "        val_true = np.loadtxt(os.path.join(output_dir, 'val_true.csv'), delimiter=',')\n",
    "        test_probs = np.loadtxt(os.path.join(output_dir, 'test_probs.csv'), delimiter=',')\n",
    "        test_true = np.loadtxt(os.path.join(output_dir, 'test_true.csv'), delimiter=',')\n",
    "        \n",
    "        # Compute ROC curve and AUC\n",
    "        fpr, tpr, _ = roc_curve(test_true, test_probs[:, 1])  # Assuming binary classification\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.plot(fpr, tpr, label=f'{experiment_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for Different Models')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(f'augmented_results/{title}_roc_curve_comparison.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, num_classes, experiment_name, learning_rate):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    model = GenericClassifier(model_name=model_name, num_classes=num_classes, learning_rate=learning_rate, class_weights=class_weights)\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor='val_acc', patience=3, mode='max')\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max')\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10, \n",
    "        accelerator='auto',  # Use 'auto' to let Lightning handle device selection\n",
    "        logger=TensorBoardLogger(\"logs\", name=experiment_name),\n",
    "        callbacks=[checkpoint_callback, early_stop_callback]\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "    \n",
    "    trainer.test(model, test_dataloader)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    time_taken = end - start\n",
    "    \n",
    "    print(f\"Time taken: {time_taken} seconds.\")\n",
    "    \n",
    "    save_metrics(\n",
    "        model.val_true, model.val_preds, \n",
    "        model.test_true, model.test_preds, \n",
    "        model.val_probs, model.test_probs, \n",
    "        experiment_name,\n",
    "        time_taken    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | VGG  | 134 M \n",
      "-------------------------------\n",
      "8.2 K     Trainable params\n",
      "134 M     Non-trainable params\n",
      "134 M     Total params\n",
      "537.075   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 124/124 [02:51<00:00,  0.72it/s, v_num=10, train_loss_step=0.499, val_loss=0.508, val_acc=0.671, train_loss_epoch=0.541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6963562965393066     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49947211146354675    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6963562965393066    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49947211146354675   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1224.0309569835663 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[492 313]\n",
      " [ 12 170]]\n",
      "Test Confusion Matrix:\n",
      " [[519 276]\n",
      " [ 24 169]]\n",
      "Validation Precision:  0.6640786749482401\n",
      "Test Precision:  0.6677881929356261\n",
      "Validation Recall:  0.7726230291447682\n",
      "Test Recall:  0.7642389285365139\n",
      "Validation F1-Score:  0.631498532427325\n",
      "Test F1-Score:  0.6527826588132758\n"
     ]
    }
   ],
   "source": [
    "train_model('vgg', num_classes, 'vgg_augmented_1e-3_reprodutible3', 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Train Model"
=======
    "Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/vgg_augmented_1e-4_reprod\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | VGG  | 134 M \n",
      "-------------------------------\n",
      "8.2 K     Trainable params\n",
      "134 M     Non-trainable params\n",
      "134 M     Total params\n",
      "537.075   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 124/124 [02:51<00:00,  0.72it/s, v_num=0, train_loss_step=0.619, val_loss=0.535, val_acc=0.650, train_loss_epoch=0.563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:11<00:00,  1.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.681174099445343     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5265136361122131     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.681174099445343    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5265136361122131    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1219.7553510665894 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[472 333]\n",
      " [ 12 170]]\n",
      "Test Confusion Matrix:\n",
      " [[498 297]\n",
      " [ 18 175]]\n",
      "Validation Precision:  0.6565893892841299\n",
      "Test Precision:  0.6679394954670872\n",
      "Validation Recall:  0.7602006688963211\n",
      "Test Recall:  0.7665754228174797\n",
      "Validation F1-Score:  0.6143505121947076\n",
      "Test F1-Score:  0.6430205949656751\n"
     ]
    }
   ],
   "source": [
    "train_model('vgg', num_classes, 'vgg_augmented_1e-4_reprod', 1e-4)"
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, num_classes, experiment_name, learning_rate):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    model = GenericClassifier(model_name=model_name, num_classes=num_classes, learning_rate=learning_rate, class_weights=class_weights)\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor='val_acc', patience=3, mode='max')\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max')\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10, \n",
    "        accelerator='auto',  # Use 'auto' to let Lightning handle device selection\n",
    "        logger=TensorBoardLogger(\"logs\", name=experiment_name),\n",
    "        callbacks=[checkpoint_callback, early_stop_callback]\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "    \n",
    "    trainer.test(model, test_dataloader)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    time_taken = end - start\n",
    "    \n",
    "    print(f\"Time taken: {time_taken} seconds.\")\n",
    "    \n",
    "    #printar acuracia:\n",
    "    \n",
    "    save_metrics(\n",
    "        model.val_true, model.val_preds, \n",
    "        model.test_true, model.test_preds, \n",
    "        model.val_probs, model.test_probs, \n",
    "        experiment_name,\n",
    "        time_taken    \n",
    "    )"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/vgg_augmented_1e-5_reprod\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | VGG  | 134 M \n",
      "-------------------------------\n",
      "8.2 K     Trainable params\n",
      "134 M     Non-trainable params\n",
      "134 M     Total params\n",
      "537.075   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 124/124 [02:52<00:00,  0.72it/s, v_num=0, train_loss_step=0.592, val_loss=0.535, val_acc=0.666, train_loss_epoch=0.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 124/124 [02:52<00:00,  0.72it/s, v_num=0, train_loss_step=0.592, val_loss=0.535, val_acc=0.666, train_loss_epoch=0.560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6902834177017212     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5230734944343567     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6902834177017212    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5230734944343567    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1735.603232383728 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[484 321]\n",
      " [  9 173]]\n",
      "Test Confusion Matrix:\n",
      " [[510 285]\n",
      " [ 21 172]]\n",
      "Validation Precision:  0.6659734255282457\n",
      "Test Precision:  0.6684097961403899\n",
      "Validation Recall:  0.7758958432871477\n",
      "Test Recall:  0.7663505719034118\n",
      "Validation F1-Score:  0.6287985156955169\n",
      "Test F1-Score:  0.6492307692307692\n"
     ]
    }
   ],
   "source": [
    "train_model('vgg', num_classes, 'vgg_augmented_1e-5_reprod', 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/resnet_augmented_1e-3\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "1.0 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.710    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 124/124 [02:17<00:00,  0.90it/s, v_num=0, train_loss_step=0.340, val_loss=0.445, val_acc=0.728, train_loss_epoch=0.478]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:07<00:00,  2.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7327935099601746     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4517155587673187     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7327935099601746    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4517155587673187    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 975.1150419712067 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[559 246]\n",
      " [ 22 160]]\n",
      "Test Confusion Matrix:\n",
      " [[561 234]\n",
      " [ 30 163]]\n",
      "Validation Precision:  0.6781114606208084\n",
      "Test Precision:  0.679908961884182\n",
      "Validation Recall:  0.7867654085045389\n",
      "Test Recall:  0.7751099814253593\n",
      "Validation F1-Score:  0.6754277468563183\n",
      "Test F1-Score:  0.6810330912025826\n"
     ]
    }
   ],
   "source": [
    "train_model('resnet', num_classes, 'resnet_augmented_1e-3', 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/resnet_augmented_1e-4\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "1.0 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.710    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 124/124 [02:17<00:00,  0.90it/s, v_num=0, train_loss_step=0.536, val_loss=0.503, val_acc=0.700, train_loss_epoch=0.531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 124/124 [02:17<00:00,  0.90it/s, v_num=0, train_loss_step=0.536, val_loss=0.503, val_acc=0.700, train_loss_epoch=0.531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:07<00:00,  2.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7236841917037964     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5015298128128052     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7236841917037964    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5015298128128052    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1387.1772632598877 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[528 277]\n",
      " [ 19 163]]\n",
      "Test Confusion Matrix:\n",
      " [[546 249]\n",
      " [ 24 169]]\n",
      "Validation Precision:  0.6678598138607279\n",
      "Test Precision:  0.6811004784688995\n",
      "Validation Recall:  0.775752508361204\n",
      "Test Recall:  0.7812200606119855\n",
      "Validation F1-Score:  0.6525904221922031\n",
      "Test F1-Score:  0.676595744680851\n"
     ]
    }
   ],
   "source": [
    "train_model('resnet', num_classes, 'resnet_augmented_1e-4', 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/resnet_augmented_1e-5\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "1.0 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.710    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 124/124 [02:17<00:00,  0.90it/s, v_num=0, train_loss_step=0.642, val_loss=0.703, val_acc=0.561, train_loss_epoch=0.712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5668016076087952     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6977707147598267     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5668016076087952    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6977707147598267    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 561.0937669277191 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[476 329]\n",
      " [104  78]]\n",
      "Test Confusion Matrix:\n",
      " [[472 323]\n",
      " [105  88]]\n",
      "Validation Precision:  0.5061679234093027\n",
      "Test Precision:  0.5160680927863308\n",
      "Validation Recall:  0.5099378881987577\n",
      "Test Recall:  0.5248346205233486\n",
      "Validation F1-Score:  0.47611015427237013\n",
      "Test F1-Score:  0.48971868785357087\n"
     ]
    }
   ],
   "source": [
    "train_model('resnet', num_classes, 'resnet_augmented_1e-5', 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/alexnet_augmented_1e-3\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | AlexNet | 57.0 M\n",
      "----------------------------------\n",
      "8.2 K     Trainable params\n",
      "57.0 M    Non-trainable params\n",
      "57.0 M    Total params\n",
      "228.048   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 124/124 [02:11<00:00,  0.94it/s, v_num=0, train_loss_step=0.616, val_loss=0.493, val_acc=0.691, train_loss_epoch=0.534]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:06<00:00,  2.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6993927359580994     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5052351355552673     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6993927359580994    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5052351355552673    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 667.3936235904694 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[512 293]\n",
      " [ 12 170]]\n",
      "Test Confusion Matrix:\n",
      " [[525 270]\n",
      " [ 27 166]]\n",
      "Validation Precision:  0.6721349314955567\n",
      "Test Precision:  0.6659104507379338\n",
      "Validation Recall:  0.7850453893932154\n",
      "Test Recall:  0.7602404927167856\n",
      "Validation F1-Score:  0.6488179606978494\n",
      "Test F1-Score:  0.6536659809291802\n"
     ]
    }
   ],
   "source": [
    "train_model('alexnet', num_classes, 'alexnet_augmented_1e-3', 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/alexnet_augmented_1e-4\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | AlexNet | 57.0 M\n",
      "----------------------------------\n",
      "8.2 K     Trainable params\n",
      "57.0 M    Non-trainable params\n",
      "57.0 M    Total params\n",
      "228.048   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 124/124 [02:11<00:00,  0.94it/s, v_num=0, train_loss_step=0.360, val_loss=0.511, val_acc=0.704, train_loss_epoch=0.537]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:06<00:00,  2.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7206477522850037     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5172664523124695     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7206477522850037    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5172664523124695    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 931.3595888614655 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[525 280]\n",
      " [ 12 170]]\n",
      "Test Confusion Matrix:\n",
      " [[547 248]\n",
      " [ 28 165]]\n",
      "Validation Precision:  0.677715704531347\n",
      "Test Precision:  0.6754100431624381\n",
      "Validation Recall:  0.7931199235547062\n",
      "Test Recall:  0.7714862971290775\n",
      "Validation F1-Score:  0.6601944952743873\n",
      "Test F1-Score:  0.671547300715473\n"
     ]
    }
   ],
   "source": [
    "train_model('alexnet', num_classes, 'alexnet_augmented_1e-4', 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/alexnet_augmented_1e-5\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | AlexNet | 57.0 M\n",
      "----------------------------------\n",
      "8.2 K     Trainable params\n",
      "57.0 M    Non-trainable params\n",
      "57.0 M    Total params\n",
      "228.048   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 124/124 [02:11<00:00,  0.94it/s, v_num=0, train_loss_step=0.608, val_loss=0.596, val_acc=0.602, train_loss_epoch=0.604]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:07<00:00,  2.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6103239059448242     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.583175539970398     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6103239059448242    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.583175539970398    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1062.7396657466888 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[426 379]\n",
      " [ 14 168]]\n",
      "Test Confusion Matrix:\n",
      " [[430 365]\n",
      " [ 20 173]]\n",
      "Validation Precision:  0.6376558085424631\n",
      "Test Precision:  0.6385584469227592\n",
      "Validation Recall:  0.726134734830387\n",
      "Test Recall:  0.7186267800697363\n",
      "Validation F1-Score:  0.5726213495959145\n",
      "Test F1-Score:  0.582043632807564\n"
     ]
    }
   ],
   "source": [
    "train_model('alexnet', num_classes, 'alexnet_augmented_1e-5', 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | AlexNet | 57.0 M\n",
      "----------------------------------\n",
      "8.2 K     Trainable params\n",
      "57.0 M    Non-trainable params\n",
      "57.0 M    Total params\n",
      "228.048   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 124/124 [02:11<00:00,  0.94it/s, v_num=1, train_loss_step=0.538, val_loss=0.580, val_acc=0.634, train_loss_epoch=0.594]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:07<00:00,  2.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6609311699867249     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5714659094810486     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6609311699867249    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5714659094810486    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1062.5809938907623 seconds.\n",
      "Validation Confusion Matrix:\n",
      " [[456 349]\n",
      " [ 12 170]]\n",
      "Test Confusion Matrix:\n",
      " [[484 311]\n",
      " [ 24 169]]\n",
      "Validation Precision:  0.6509559804357492\n",
      "Test Precision:  0.6524196194225722\n",
      "Validation Recall:  0.7502627806975632\n",
      "Test Recall:  0.7422263499201616\n",
      "Validation F1-Score:  0.600719654225307\n",
      "Test F1-Score:  0.6225649119245906\n"
     ]
    }
   ],
   "source": [
    "train_model('alexnet', num_classes, 'alexnet_augmented_1e-5', 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/efficientnet_augmented_1e-3\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | EfficientNet | 4.0 M \n",
      "---------------------------------------\n",
      "2.6 K     Trainable params\n",
      "4.0 M     Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.040    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  32%|███▏      | 40/124 [00:45<01:35,  0.88it/s, v_num=0, train_loss_step=0.511, val_loss=0.583, val_acc=0.698, train_loss_epoch=0.493] "
     ]
    }
   ],
   "source": [
    "train_model('efficientnet', num_classes, 'efficientnet_augmented_1e-3', 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('efficientnet', num_classes, 'efficientnet_augmented_1e-4', 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('efficientnet', num_classes, 'efficientnet_augmented_1e-5', 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('inception', num_classes, 'inception_augmented_1e-3', 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('inception', num_classes, 'inception_augmented_1e-4', 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('inception', num_classes, 'inception_augmented_1e-5', 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced results"
>>>>>>> 9561741a87d8ffa76b21c4ca50e4e369cc4f0ca6
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
